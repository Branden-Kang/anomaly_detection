{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Control Charts For Anomaly Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMf0r3ahejQi53iRwuJov1d"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://unhypedai.medium.com/control-charts-for-anomaly-detection-75b615ab8f9b)"
      ],
      "metadata": {
        "id": "4f0E9OGefloj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation\n"
      ],
      "metadata": {
        "id": "YOLnKltbfpty"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tf6WH221fE5L"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from os.path import join, isdir\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "class Config:\n",
        "  DATASET_PATH =\"UCSD_Anomaly_Dataset.v1p2/UCSDped1/Train\"\n",
        "  SINGLE_TEST_PATH = \"UCSD_Anomaly_Dataset.v1p2/UCSDped1/Test/Test001\"\n",
        "  SEQUENCE_SIZE = 10\n",
        "  NO_OF_STRIDES = 3\n",
        "  INPUT_SIZE = 256\n",
        "  BATCH_SIZE = 4\n",
        "  EPOCHS = 3\n",
        "  MODEL_PATH = \"model.hdf5\"\n",
        "\n",
        "def get_strided_frames(stride, frames_list):\n",
        "    \"\"\" For data augmenting purposes.\n",
        "    Parameters\n",
        "    ----------\n",
        "    stride : int\n",
        "        The stride between two consecutive frames\n",
        "    frames_list : list\n",
        "        A list of sorted frames in a folder each of shape 256 X 256\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of clips , each of desired sequence size length\n",
        "    \"\"\"\n",
        "    strided_frames = []\n",
        "    clip = np.zeros(shape=(Config.SEQUENCE_SIZE, Config.INPUT_SIZE, Config.INPUT_SIZE, 1))\n",
        "    count = 0\n",
        "    for start in range(Config.NO_OF_STRIDES):\n",
        "        for i in range(start, len(frames_list), Config.NO_OF_STRIDES):\n",
        "            clip[count, :, :, 0] = frames_list[i]\n",
        "            count = count + 1\n",
        "            if count == Config.SEQUENCE_SIZE:\n",
        "                strided_frames.append(np.copy(clip))\n",
        "                count = 0\n",
        "    return strided_frames\n",
        "\n",
        "\n",
        "def get_training_data():\n",
        "    \"\"\" For getting list of all training data\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of training sequences of shape (NUMBER_OF_SEQUENCES,SINGLE_SEQUENCE_SIZE,FRAME_WIDTH,FRAME_HEIGHT,1) \n",
        "        Used for training the model\n",
        "    \"\"\"\n",
        "    training_data = []\n",
        "    # loop over the training folders (Train000,Train001,..)\n",
        "    for folder_name in sorted(listdir(Config.DATASET_PATH)):\n",
        "        folder_path = join(Config.DATASET_PATH, folder_name)\n",
        "        if isdir(folder_path):\n",
        "            frames_list = []\n",
        "            # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
        "            for file_name in sorted(listdir(folder_path)):\n",
        "                file_path = join(folder_path, file_name)\n",
        "                if str(file_path)[-3:] == \"tif\":\n",
        "                    # read image and resize it to desired input size\n",
        "                    img = Image.open(file_path).resize((Config.INPUT_SIZE, Config.INPUT_SIZE))\n",
        "                    # normalization\n",
        "                    img = np.array(img, dtype=np.float32) / 256.0\n",
        "                    frames_list.append(img)\n",
        "            # get the sequences from the list of images after applying data augmentation\n",
        "            for stride in range(1, Config.NO_OF_STRIDES):\n",
        "                training_data.extend(get_strided_frames(stride=stride, frames_list=frames_list))\n",
        "    return training_data\n",
        "\n",
        "def get_training_data_subset():\n",
        "    \"\"\" For getting list of all training data\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of training sequences of shape (NUMBER_OF_SEQUENCES,SINGLE_SEQUENCE_SIZE,FRAME_WIDTH,FRAME_HEIGHT,1) \n",
        "        Used for finding Center, Upper limit and Lower limit\n",
        "    \"\"\"\n",
        "    training_data = []\n",
        "    # loop over the training folders (Train000,Train001,..)\n",
        "    for folder_name in sorted(listdir(Config.DATASET_PATH)):\n",
        "        folder_path = join(Config.DATASET_PATH, folder_name)\n",
        "        if isdir(folder_path):\n",
        "            frames_list = []\n",
        "            # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
        "            for file_name in sorted(listdir(folder_path)):\n",
        "                file_path = join(folder_path, file_name)\n",
        "                if str(file_path)[-3:] == \"tif\":\n",
        "                    # read image and resize it to desired input size\n",
        "                    img = Image.open(file_path).resize((Config.INPUT_SIZE, Config.INPUT_SIZE))\n",
        "                    # normalization\n",
        "                    img = np.array(img, dtype=np.float32) / 256.0\n",
        "                    frames_list.append(img)\n",
        "            # get the sequences from the list of images after applying data augmentation\n",
        "            for stride in range(1, Config.NO_OF_STRIDES):\n",
        "                training_data.extend(get_strided_frames(stride=stride, frames_list=frames_list))\n",
        "                if len(training_data)==200:\n",
        "                  break\n",
        "    return training_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model\n"
      ],
      "metadata": {
        "id": "1MsI-YXgftov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow.keras\n",
        "# from tensorflow.keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D\n",
        "# from tensorflow.keras.models import Sequential, load_model\n",
        "# from keras_layer_normalization import LayerNormalization\n",
        "\n",
        "# def get_model(reload_model=True):\n",
        "#     \"\"\"\n",
        "#     Parameters\n",
        "#     ----------\n",
        "#     reload_model : bool\n",
        "#         Load saved model or retrain it\n",
        "#     \"\"\"\n",
        "#     if not reload_model:\n",
        "#         return load_model(Config.MODEL_PATH,custom_objects={'LayerNormalization': LayerNormalization})\n",
        "#     training_set = get_training_set()\n",
        "#     training_set = np.array(training_set)\n",
        "#     seq = Sequential()\n",
        "#     # # # # # Encoder\n",
        "#     seq.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, padding=\"same\"), batch_input_shape=(None, 10, 256, 256, 1)))\n",
        "#     seq.add(LayerNormalization())\n",
        "#     seq.add(TimeDistributed(Conv2D(64, (5, 5), strides=2, padding=\"same\")))\n",
        "#     seq.add(LayerNormalization())\n",
        "#     # # # # # Bottleneck\n",
        "#     seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "#     seq.add(LayerNormalization())\n",
        "#     seq.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
        "#     seq.add(LayerNormalization())\n",
        "#     seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "#     seq.add(LayerNormalization())\n",
        "#     # # # # # Decoder\n",
        "#     seq.add(TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, padding=\"same\")))\n",
        "#     seq.add(LayerNormalization())\n",
        "#     seq.add(TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, padding=\"same\")))\n",
        "#     seq.add(LayerNormalization())\n",
        "#     seq.add(TimeDistributed(Conv2D(1, (11, 11), activation=\"sigmoid\", padding=\"same\")))\n",
        "#     print(seq.summary())\n",
        "#     seq.compile(loss='mse', optimizer=tensorflow.keras.optimizers.Adam(lr=1e-4, decay=1e-5, epsilon=1e-6))\n",
        "#     seq.fit(training_set, training_set,\n",
        "#             batch_size=Config.BATCH_SIZE, epochs=Config.EPOCHS, shuffle=False)\n",
        "#     seq.save(Config.MODEL_PATH)\n",
        "    return seq"
      ],
      "metadata": {
        "id": "0rCZMU_ffnPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Determining Control Line, Lower Limit Line, and Upper Limit Line\n"
      ],
      "metadata": {
        "id": "vJw_ZqUcfzq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=get_model(False)\n",
        "training_set = get_training_data_subset()\n",
        "training_set = np.array(training_set)\n",
        "training_set = training_set.reshape(-1,10,256,256,1)\n",
        "\n",
        "data_points = []\n",
        "for train_data in tqdm(training_set):\n",
        "    train_data = train_data.reshape(-1,10,256,256,1)\n",
        "    reconstructed_data = model.predict(train_data)\n",
        "    sequences_reconstruction_cost = np.array(np.average(np.subtract(train_data, reconstructed_data)))\n",
        "    data_points.append(sequences_reconstruction_cost)\n",
        "\n",
        "center_line = np.mean(data_points)\n",
        "print('Center Line is: ' + str(center_line))\n",
        "sd = np.std(data_points_line)\n",
        "print('Standard deviation is: ' + str(sd))\n",
        "lim_upper = center_line + sd\n",
        "print('Upper control limit is: ' + str(lim_upper))\n",
        "lim_lower = center_line - sd\n",
        "print ('Lower control limit is: ' + str(lim_lower))"
      ],
      "metadata": {
        "id": "b6HTeDDOfyag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detecting Anomaly with Control charts\n"
      ],
      "metadata": {
        "id": "CF1Dewjyf6xA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_single_test():\n",
        "    sz = 200\n",
        "    test = np.zeros(shape=(sz, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for f in sorted(listdir(Config.SINGLE_TEST_PATH)):\n",
        "        if str(join(Config.SINGLE_TEST_PATH, f))[-3:] == \"tif\":\n",
        "            img = Image.open(join(Config.SINGLE_TEST_PATH, f)).resize((256, 256))\n",
        "            img = np.array(img, dtype=np.float32) / 256.0\n",
        "            test[cnt, :, :, 0] = img\n",
        "            cnt = cnt + 1\n",
        "    return test\n",
        "\n",
        "test = get_single_test()\n",
        "sz = test.shape[0] - 10 + 1\n",
        "sequences = np.zeros((sz, 10, 256, 256, 1))\n",
        "# apply the sliding window technique to get the sequences\n",
        "for i in range(0, sz):\n",
        "    clip = np.zeros((10, 256, 256, 1))\n",
        "    for j in range(0, 10):\n",
        "        clip[j] = test[i + j, :, :, :]\n",
        "    sequences[i] = clip\n",
        "\n",
        "reconstructed_sequences = model.predict(sequences,batch_size=4)\n",
        "sequences_reconstruction_cost_res = np.array([np.average(np.subtract(sequences[i],reconstructed_sequences[i])) for i in range(0,sz)])\n",
        "\n",
        "\n",
        "plt.plot(sequences_reconstruction_cost_res)\n",
        "plt.hlines(y=center_avg, xmin=0, xmax=200, colors='red', linestyles='-', lw=2, label='Center Line')\n",
        "plt.hlines(y=lim_lower_avg, xmin=0, xmax=200, colors='aqua', linestyles='-', lw=2, label='Lower Limit Line')\n",
        "plt.hlines(y=lim_upper_avg, xmin=0, xmax=200, colors='aqua', linestyles='-', lw=2, label='Upper Limit Line')\n",
        "plt.ylabel('Reconstruction normality')\n",
        "plt.xlabel('frame t')\n",
        "plt.title('Anomaly Detection with Control Chart')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vWgc4Nhuf5Y9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}