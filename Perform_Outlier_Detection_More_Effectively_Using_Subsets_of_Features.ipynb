{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHsmTGzc2xoU2IdoulhOC7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://towardsdatascience.com/perform-outlier-detection-more-effectively-using-subsets-of-features-d984bde99981)"
      ],
      "metadata": {
        "id": "b0L8kMXtC9fZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qeZcQr5C6NQ",
        "outputId": "13b4245c-431d-43e5-d04d-0bfc61b777d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'E', 'F', 'G', 'H']\n",
            "['B', 'C', 'D', 'F', 'H']\n",
            "['A', 'B', 'C', 'D', 'E']\n",
            "['B', 'D', 'E', 'F', 'G']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def get_random_subspaces(features_arr, num_base_detectors,\n",
        "                         num_feats_per_detector):\n",
        "    num_feats = len(features_arr)\n",
        "    feat_sets_arr = []\n",
        "    ft_used_counts = np.zeros(num_feats)\n",
        "    ft_pair_mtx = np.zeros((num_feats, num_feats))\n",
        "\n",
        "    # Each loop generates one subspace, which is one set of features\n",
        "    for _ in range(num_base_detectors):\n",
        "        # Get the set of features with the minimum count\n",
        "        min_count = ft_used_counts.min()\n",
        "        idxs = np.where(ft_used_counts == min_count)[0]\n",
        "\n",
        "        # Pick one of these randomly and add to the current set\n",
        "        feat_set = [np.random.choice(idxs)]\n",
        "\n",
        "        # Find the remaining set of features\n",
        "        while len(feat_set) < num_feats_per_detector:\n",
        "            mtx_with_set = ft_pair_mtx[:, feat_set]\n",
        "            sums = mtx_with_set.sum(axis=1)\n",
        "            min_sum = sums.min()\n",
        "            min_idxs = np.where(sums==min_sum)[0]\n",
        "            new_feat = np.random.choice(min_idxs)\n",
        "            feat_set.append(new_feat)\n",
        "            feat_set = list(set(feat_set))\n",
        "\n",
        "            # Updates ft_pair_mtx\n",
        "            for c in feat_set:\n",
        "                ft_pair_mtx[c][new_feat] += 1\n",
        "                ft_pair_mtx[new_feat][c] += 1\n",
        "\n",
        "        # Updates ft_used_counts\n",
        "        for c in feat_set:\n",
        "            ft_used_counts[c] += 1\n",
        "\n",
        "        feat_sets_arr.append(feat_set)\n",
        "\n",
        "    return feat_sets_arr\n",
        "\n",
        "np.random.seed(0)\n",
        "features_arr = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
        "num_base_detectors = 4\n",
        "num_feats_per_detector = 5\n",
        "\n",
        "feat_sets_arr = get_random_subspaces(features_arr,\n",
        "                                     num_base_detectors,\n",
        "                                     num_feats_per_detector)\n",
        "for feat_set in feat_sets_arr:\n",
        "    print([features_arr[x] for x in feat_set])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyod"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVZG4X60DPYD",
        "outputId": "995b5d7d-a0cb-425b-f817-8fb61efe0d52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyod\n",
            "  Downloading pyod-2.0.2.tar.gz (165 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/165.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.8/165.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pyod) (1.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pyod) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from pyod) (1.26.4)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.10/dist-packages (from pyod) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from pyod) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from pyod) (1.5.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51->pyod) (0.43.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->pyod) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->pyod) (1.16.0)\n",
            "Building wheels for collected packages: pyod\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-2.0.2-py3-none-any.whl size=198469 sha256=1b691cc7f530b47645526451ad2631200048719196760d567144a31db843c321\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/c2/20/34d1f15b41b701ba69f42a32304825810d680754d509f91391\n",
            "Successfully built pyod\n",
            "Installing collected packages: pyod\n",
            "Successfully installed pyod-2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pyod.models.sod import SOD\n",
        "\n",
        "np.random.seed(0)\n",
        "d = np.random.randn(100, 35)\n",
        "d = pd.DataFrame(d)\n",
        "\n",
        "#A Ensure features 8 and 9 are correlated, while all others are irrelevant\n",
        "d[9] = d[9] + d[8]\n",
        "\n",
        "# Insert a single outlier\n",
        "d.loc[99, 8] = 3.5\n",
        "d.loc[99, 9] = -3.8\n",
        "\n",
        "#C Execute SOD, flagging only 1 outlier\n",
        "clf = SOD(ref_set=3, contamination=0.01)\n",
        "d['SOD Scores'] = clf.fit (d)\n",
        "d['SOD Scores'] = clf.labels_"
      ],
      "metadata": {
        "id": "m5N0Sc41DT8a"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}